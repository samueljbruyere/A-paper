
Sovereign Swarm Intelligence: An Analysis of Emerging Decentralized Compute Architectures and AI Training Frameworks


I. The Strategic Imperative: Sovereign AI and the Shift to Decentralized Infrastructure


1.1 Defining Sovereign AI in 2025: Beyond Data Residency to Computational Independence

The concept of Sovereign AI has matured significantly between 2024 and 2025, evolving from a narrow focus on data residency to a comprehensive strategic doctrine demanding national capabilities across the entire artificial intelligence value chain.1 In the current landscape, true sovereignty is defined by a nation's capacity to produce and govern AI using its own infrastructure, proprietary and public data, specialized workforce, and domestic business networks.1 This paradigm shift is driven by the recognition that AI is a foundational technology, projected to generate trillions of dollars in economic value and fundamentally reshape national competitiveness, defense, and scientific discovery.1
The imperative is no longer merely to control where data is stored but to own every layer of the AI stack, from localized data storage and processing to independent model orchestration and governance.3 This entails the development of sovereign foundation models, such as large language models (LLMs), trained on local datasets to reflect and preserve specific dialects, cultures, and societal practices.1 The goal is to create a unified data and AI architecture that ensures models are trained, deployed, and governed in alignment with national regulations and strategic interests, free from external dependencies and potential vulnerabilities.3
While major cloud providers offer "sovereign cloud" solutions that provide robust data residency, access controls, and even air-gapped deployments, these often represent a compromise rather than true computational independence.5 They provide a degree of control within a foreign-owned technological ecosystem. In contrast, the emerging doctrine of Sovereign AI pushes for the creation of sovereign-native infrastructure, such as national "AI Factories"—next-generation data centers that serve as the bedrock of modern economies by hosting the full stack of accelerated computing platforms required for AI production.1 These sovereign AI clouds, running in an organization's or nation's own data centers with limited or no external access, represent the ultimate expression of this strategic objective, ensuring complete control over high-value AI workloads and sensitive data.6

1.2 The Inevitability of Decentralization: Power Constraints, Geopolitics, and Capability Proliferation

The trajectory of AI development is forcing a strategic pivot away from the centralized, single-site data center model that defined the previous decade. This shift is not a matter of choice but of necessity, driven by a confluence of physical, geopolitical, and technological pressures.
The most significant physical constraint is the exponential growth in the computational and energy requirements for training frontier AI models. As of 2025, training compute for large models doubles every five months, with power usage doubling annually.7 Leading-edge training runs already demand power well in excess of 100 megawatts, with projections suggesting requirements could reach 5 gigawatts or more by 2030.8 Sourcing this level of energy and building the corresponding infrastructure in a single location is becoming logistically and economically untenable. This physical reality compels a move towards distributed training, where workloads are spread across multiple, smaller data centers, often in different geographic regions.8
Geopolitically, the increasing centrality of AI to economic power and national defense has made technological dependence a critical vulnerability.2 Governments now recognize that reliance on foreign AI technologies, controlled by a small number of multinational corporations, creates unacceptable economic and security risks.2 This has fueled a renewed emphasis on developing local AI ecosystems and asserting digital sovereignty, a trend accelerated by growing geopolitical rivalries.2 The pursuit of Sovereign AI is a direct response to this threat, aiming to mitigate vulnerabilities by fostering domestic capabilities.1
Simultaneously, algorithmic advancements are making decentralized approaches technically feasible. Breakthroughs in low-communication training algorithms, such as those that allow model synchronization to occur far less frequently, enable effective training over standard internet speeds.8 This innovation is a key driver of AI capability proliferation, as it dramatically lowers the barrier to entry for training powerful models. It creates a pathway for a wider range of actors—from startups and academic labs to nations without hyperscale infrastructure—to develop and deploy advanced AI systems.8 This democratization of AI development, however, presents a fundamental tension. The very tools that enable nations to achieve AI sovereignty—open, permissionless, and global P2P networks—are inherently resistant to the centralized control that sovereignty implies. A nation adopting these transnational protocols to build its own capabilities is simultaneously embracing an infrastructure that transcends and potentially undermines national borders. This paradox suggests that true, long-term sovereignty may require not just the use of these open frameworks, but the development of national-level forks or entirely new protocols, a path that could sacrifice the powerful network effects that make the open ecosystem so compelling.

1.3 Architectural Principles of Sovereign Mesh Networks: Trust, Resilience, and Autonomy

To meet the demands of Sovereign AI in a decentralized world, a new infrastructure model is emerging: the "decentralized mesh hyperscaler".10 This architecture represents a foundational shift from the static, centralized cloud to a dynamic, distributed network of collaborating nodes. It is built on three core principles: local autonomy, resilience through redundancy, and the efficient aggregation of underutilized resources.10
Unlike traditional hub-and-spoke models, a mesh architecture distributes computing power across a web of interconnected nodes. This design is inherently resilient; if one node fails, others in the network can seamlessly absorb its workload, minimizing downtime and ensuring system stability.10 This approach moves away from owning servers towards sharing compute across networks, and from global control to local autonomy.10
These architectural principles align directly with the concepts of swarm intelligence, which describes the collective problem-solving capabilities that emerge from groups of decentralized, self-organized agents.11 In a swarm, each agent follows simple local rules and interacts with its immediate neighbors. There is no central leader, yet the group as a whole exhibits complex, adaptive, and intelligent behavior that is robust and scalable.11 The strengths of swarm intelligence—resilience through redundancy, dynamic adaptability, and emergent problem-solving—are precisely the qualities required for a sovereign compute network operating in a dynamic and potentially untrusted global environment.12 A system where intelligence is distributed and decisions are made locally is far more adaptable and difficult to disable than a monolithic, centrally controlled one. This theoretical foundation provides the blueprint for the sovereign, Tor-like mesh models that are now being realized in practice.

II. Analysis of Peer-to-Peer Compute Architectures and Mesh Models

The foundation of any decentralized AI strategy is the underlying peer-to-peer (P2P) compute fabric. This section analyzes the architectures of both general-purpose P2P cloud networks and specialized, security-first mesh models that provide the infrastructure for sovereign swarm deployments.

2.1 General-Purpose Decentralized Cloud Networks

General-purpose P2P compute marketplaces represent the first generation of decentralized infrastructure, creating open markets for underutilized computing resources. A prominent example is the Akash Network, which operates as an open-source, decentralized P2P marketplace for cloud compute.13
Akash provides a platform where users can deploy applications globally by leasing compute resources from a distributed network of providers, often at a fraction of the cost of traditional cloud services—claiming savings of up to 80%.15 The infrastructure is secured by blockchain technology, offering censorship resistance and permissionless access.15 The network is explicitly optimized for AI and machine learning workloads, providing scalable GPU resources for tasks ranging from data-intensive analytics to LLM training and real-time inference.14 While platforms like Akash provide a crucial layer of resource aggregation and cost efficiency, their primary focus is on creating a market. Security is a feature, but it is not the fundamental organizing principle of the architecture itself.

2.2 Specialized Cybersecurity Mesh Architectures: A Case Study of the Naoris Protocol

A more advanced and strategically significant architectural pattern emerges when the network fabric and the security model become one and the same. This convergence is exemplified by the Naoris Protocol, which is designed from the ground up as a decentralized cybersecurity mesh architecture.16 Its purpose is not merely to provide compute, but to generate and maintain a state of verifiable trust across a network of otherwise untrusted devices. This makes its architecture exceptionally relevant for sovereign deployments where security and integrity are paramount.
Architecture: The Sub-Zero Layer and dPoSec Consensus
The Naoris Protocol operates at a foundational "Sub-Zero Layer," designed to function beneath traditional L0, L1, and L2 blockchains, as well as conventional Web2 infrastructure.17 This positioning allows it to provide a universal trust and security fabric without requiring disruptive hard forks or modifications to the systems it protects.17
The core of the architecture is the transformation of every participating device—whether a server, an IoT sensor, or a blockchain validator—into a trusted validator node within a decentralized mesh.16 These nodes continuously validate the operational state and "cyber-health" of every other asset in the network, creating a self-healing and self-protecting system that eliminates single points of failure.16
This continuous validation process is governed by a novel consensus mechanism called Decentralized Proof of Security (dPoSec).16 Unlike Proof-of-Work or Proof-of-Stake, which validate transactions, dPoSec is a hybrid consensus model that validates the real-time integrity and security posture of devices.20 Each node's trust score and influence within the network are based on its observed behavior and reliability, creating a dynamic consensus rooted in continuous security validation.19 This process is designed to be extremely high-throughput, with the protocol's purpose-built blockchain capable of recording 50k to 1 million processes or state changes per second.21
Security Model: Post-Quantum Cryptography and Decentralized Swarm AI
The Naoris Protocol's security model is built on two additional pillars designed for long-term resilience:
Post-Quantum Cryptography (PQC): The protocol is aligned with NIST, NATO, and ETSI post-quantum standards, employing algorithms like Dilithium-5 to secure the network against the future threat of quantum computers capable of breaking current encryption standards.18 This forward-looking approach is critical for sovereign infrastructure intended to remain secure for decades.
Decentralized Swarm AI: The protocol employs a swarm AI system that provides continuous, dynamic validation of trust across every device.16 This self-learning AI network coordinates threat detection and response across the entire mesh, capable of identifying and mitigating anomalies like phishing or malware in milliseconds.20 Testnet data has shown the system neutralizing hundreds of millions of threats over a six-month period, demonstrating its effectiveness at scale.20
This architecture represents a paradigm shift. For sovereign entities, the implication is profound: instead of attempting to secure a fundamentally untrusted P2P compute market with external tools, the most robust strategy is to build upon a foundational protocol whose very purpose is the decentralized generation and enforcement of trust. The act of participating in the Naoris network is the security mechanism, making the fabric itself the first and strongest line of defense.
Signal Density Summary: Naoris Protocol
Relevance to Query: High.
Summary: The Naoris Protocol is a direct implementation of a sovereign, Tor-like mesh model. Its architecture explicitly integrates a decentralized cybersecurity mesh, a novel trust-based consensus mechanism (dPoSec), and swarm AI for real-time threat detection. Its use of post-quantum cryptography further aligns with the long-term security requirements of sovereign deployments. It is one of the most conceptually aligned systems with the user's core query.

III. Deep Dive: Decentralized AI Training Frameworks (2024-2025)

While P2P mesh networks provide the foundational compute layer, specialized frameworks are required to orchestrate the complex task of large-scale AI model training across distributed, unreliable, and low-bandwidth nodes. Between 2024 and 2025, several projects have demonstrated viable solutions, moving decentralized training from a theoretical concept to a practical reality. This section provides a deep dive into the leading frameworks.

3.1 Gensyn AI

Gensyn is building a decentralized AI compute network designed to democratize access to advanced AI training by linking distributed computing resources worldwide into a single, permissionless network.22 Its architecture is a comprehensive, end-to-end system with novel solutions for coordination, verification, communication, and fault tolerance.
Architecture: Ethereum Rollup, Off-Chain Execution, and the Verde Verification System
Gensyn's protocol uses a hybrid on-chain and off-chain architecture. The coordination layer is a custom Ethereum Rollup dedicated to machine learning.24 This blockchain layer handles persistent identity, tracks participation, maintains attribution, processes payments, and logs decentralized training runs, providing a transparent and auditable record of the network's activities.24
The actual computationally intensive work of model training occurs off-chain, performed by a global network of compute providers. The critical challenge in such a trustless environment is verifying that this off-chain work was performed correctly. Gensyn addresses this with its Verde verification system.25 Verde is an arbitration system for ML over untrusted nodes, which adapts the cryptographic concept of "refereed delegation." If multiple compute providers produce different results for the same task, Verde uses an efficient dispute resolution game to pinpoint the exact operation where they diverged, allowing a computationally limited referee to identify the dishonest party without re-running the entire task.25 A key enabler for Verde is the
RepOps library, which ensures bitwise reproducibility of ML operations across heterogeneous hardware, eliminating non-determinism from floating-point variations and providing a ground truth for comparison.25
Key Innovations
Gensyn has developed a suite of specialized protocols to overcome the primary obstacles of decentralized training:
Fault Tolerance:
CheckFree: A "memoryless" recovery method for pipeline-parallel training. If a node responsible for a set of model layers (a "stage") fails, CheckFree reinitializes the failed stage's weights as a weighted average of its immediate neighbors in the pipeline. This allows training to continue with minimal disruption and without the overhead of traditional checkpointing.25
SkipPipe: A novel pipeline parallelism framework that reduces training iteration time by up to 55%. It dynamically schedules microbatches to skip certain stages or process them out of order, minimizing node idle time and providing fault tolerance against up to a 50% node failure rate.25
Communication Efficiency:
NoLoCo: An optimization method that replaces the global, synchronous All-Reduce step common in distributed training with a more efficient gossip protocol. This significantly reduces communication bottlenecks, enabling effective training even in heterogeneous and low-bandwidth networks.25
Application Layer:
RL Swarm: A flagship application built on the Gensyn network, RL Swarm is a peer-to-peer system for collaborative reinforcement learning.22 It allows thousands of agents to share insights and train together over the internet, demonstrating the power of decentralized collaboration. Models trained using RL Swarm have already achieved top rankings on platforms like Hugging Face, proving the viability of the approach.22
Signal Density Summary: Gensyn AI
Relevance to Query: Very High.
Summary: Gensyn offers a complete, vertically integrated protocol for decentralized AI training. Its explicit and innovative solutions for trustless verification (Verde), fault tolerance (CheckFree, SkipPipe), and low-bandwidth communication (NoLoCo) directly address the core technical challenges of building a resilient, sovereign-capable swarm computing system.

3.2 Nous Research (Psyche Network)

Nous Research is a collective of researchers and developers focused on open-source, human-centric AI.26 Their flagship infrastructure project,
Psyche, is a decentralized AI training network designed to democratize AI development by coordinating training across globally distributed, heterogeneous, and underutilized hardware.28
Architecture: Solana-based Coordination and the DisTrO Optimization Protocol
The Psyche network employs a lean and efficient architecture. The coordination layer is built on the Solana blockchain, chosen for its high throughput and low transaction costs, making it suitable for managing the micro-transactions and state updates required for a large-scale training run.26 Smart contracts on Solana store metadata about each run, manage the list of participants, handle state transitions, and provide randomness for task assignments, ensuring a transparent and censorship-resistant process.28
The client system is built in Rust and utilizes Iroh, a modern P2P networking stack, to establish direct, end-to-end encrypted, and authenticated connections between nodes, even those behind NATs or firewalls.28 This ensures secure and reliable peer-to-peer communication without relying on centralized relays.
Key Innovations
Psyche's primary contribution is a radical solution to the bandwidth problem that has historically made internet-scale training impractical.
Communication Optimization (DisTrO): The core of Psyche is the Distributed Training Over-the-internet (DisTrO) protocol. This family of optimizers reduces the volume of data that needs to be exchanged between GPUs by a factor of 1,000x to 10,000x.26 DisTrO is inspired by JPEG compression. Instead of communicating the full gradient or weight updates, it first applies a
Discrete Cosine Transform (DCT) to translate the model's momentum tensor into the frequency domain. In this domain, most of the significant information is concentrated in a few components. DisTrO intelligently selects and shares only the top-k components with the highest energy, dramatically compressing the update size. The receiving node then uses an inverse DCT to reconstruct an approximate gradient and update its model parameters.28 This makes distributed training feasible over a standard internet connection.
Fault Tolerance and Flexibility: Psyche is explicitly designed for a dynamic and unreliable network. Training runs are divided into "epochs" (sets of training steps), which act as natural synchronization and checkpointing intervals. This structure allows new compute nodes to be dynamically added mid-training and enables the system to absorb individual node failures without halting the entire process.26 This flexibility lowers the barrier to entry for participants with idle or preemptible hardware.
The first major undertaking on the Psyche network is the pre-training of "Consilience," a 4-billion-parameter model, which is intended to be the largest distributed AI training ever conducted over the internet.29
Signal Density Summary: Nous Research (Psyche Network)
Relevance to Query: Very High.
Summary: Psyche's groundbreaking DisTrO protocol provides a powerful solution to the primary physical limitation of decentralized training: network bandwidth. Combined with its Solana-based coordination layer and built-in fault tolerance, it presents a highly viable and elegant architecture for sovereign swarm computation, particularly in environments with heterogeneous and unreliable network conditions.

3.3 Prime Intellect

Prime Intellect is building a comprehensive stack for "open superintelligence," from agentic models to the infrastructure required to train and deploy them.30 Their approach focuses on aggregating global compute resources into a unified marketplace and developing robust frameworks to make large-scale decentralized training efficient and accessible.31
Architecture: P2P Protocol with Orchestrator, Validators, and Worker Nodes
The Prime Protocol is a modular, peer-to-peer compute and intelligence network.32 Its architecture consists of several key components:
Smart Contracts: Ethereum-based contracts manage the protocol's economic layer, including roles, permissions, and provider stakes.32
Discovery Service: A secure API that allows worker nodes to register their metadata, which is then made available to the orchestrator. This shields worker IPs from public exposure, reducing the risk of DDoS attacks.32
Orchestrator: A central component (for a given training run) that coordinates compute jobs, distributes tasks, monitors the lifecycle of worker nodes via heartbeats, and provides an API for managing the run.32
Validator Network: Ensures the quality and integrity of work performed by the worker nodes through random challenges.32
Worker Nodes: The compute providers that execute AI workloads within secure Docker containers.32
Key Innovations
Prime Intellect's contributions are heavily focused on practical, robust engineering for fault tolerance and the successful execution of large-scale collaborative training runs.
Fault Tolerance (ElasticDeviceMesh): A key innovation within their prime training framework is the ElasticDeviceMesh, a distributed abstraction that manages dynamic groups of processes.35 Unlike standard PyTorch distributed tools that crash if a node leaves, ElasticDeviceMesh allows nodes to join or leave a training run seamlessly. It uses a heartbeat mechanism to detect dead nodes and resizes the process group on the fly, ensuring the run continues without requiring a full restart.35
Asynchronous Distributed Checkpointing: To prevent the lengthy process of saving large model checkpoints from blocking training, Prime Intellect implements an asynchronous system. Checkpoints are first written rapidly to a RAM-backed filesystem (/dev/shm). Subprocesses then handle the slower tasks of copying the checkpoint to persistent disk storage and uploading it to a remote location in the background.35 New nodes joining a run can quickly download the latest checkpoint directly from their peers, which serve it from memory via a sidecar HTTP server.35
Proven Execution at Scale: Prime Intellect has successfully demonstrated its architecture by training several large, collaboratively owned models. These include INTELLECT-1, the first decentralized training of a 10-billion-parameter model, and INTELLECT-2, a 32-billion-parameter model trained using decentralized reinforcement learning.30 These projects prove that the infrastructure can aggregate sufficient compute (e.g., over 360,000 exaFLOPs for INTELLECT-1) from anonymous contributors to create competitive open models.33
Signal Density Summary: Prime Intellect
Relevance to Query: High.
Summary: Prime Intellect provides a battle-tested, engineering-focused solution for decentralized AI. Its emphasis on robust fault tolerance through mechanisms like ElasticDeviceMesh and asynchronous checkpointing makes it highly suitable for deployments on unreliable, internet-scale hardware. The successful training of its INTELLECT model series serves as powerful validation of its architecture and approach.

3.4 Comparative Analysis of Other Notable Frameworks

While Gensyn, Psyche, and Prime Intellect represent the frontier of permissionless, internet-scale training, other frameworks contribute important concepts and capabilities to the decentralized AI ecosystem.
DeServe: This framework is uniquely focused on optimizing decentralized offline LLM inference rather than training.36 It addresses the high-latency environment of P2P networks by using
inter-layer model parallelism, where different layers of an LLM are processed on different nodes in a pipeline.36 This approach, combined with a microbatch scheduler, mitigates the impact of network delays and improves overall throughput. Its architecture includes on-chain components for a task registry, GPU registry, payments, and arbitration, providing a blueprint for a complete decentralized serving system.36
AIArena: This platform provides a blockchain-based framework for democratizing both AI training and AI alignment.38 Its architecture is notable for its formal, role-based structure, which includes
Task Creators, Training Nodes, Validators, and Delegators. An on-chain incentive and reward mechanism, governed by smart contracts, is used to ensure fair compensation, encourage valid contributions, and defend against malicious behavior like model theft through a multi-phase validation process.38
Flower Labs: Flower is a mature, open-source framework for federated learning (FL).39 Its key strength is its agnosticism; it is designed to work with any machine learning framework (PyTorch, TensorFlow, etc.) and on any platform (cloud, mobile, edge).41 The Flower architecture elegantly separates the persistent network infrastructure (
SuperLink server, SuperNode clients) from the transient, project-specific code (ServerApp, ClientApp), allowing multiple, distinct federated learning jobs to run on the same set of devices.42 It provides a rich ecosystem of Privacy-Enhancing Technologies (PETs), including protocols for
secure aggregation and support for differential privacy, making it a strong choice for privacy-sensitive applications.44

3.5 Comparative Matrix of Leading Decentralized Training Frameworks

The following table synthesizes the architectural and strategic differences between the three leading platforms for internet-scale decentralized AI training.
Feature
Gensyn AI
Nous Research (Psyche)
Prime Intellect
Coordination Layer
Custom Ethereum Rollup
Solana Blockchain
Ethereum Smart Contracts
Primary Communication Method
Gossip Protocol (NoLoCo) for updates
Bandwidth-Compressed Momentum (DisTrO)
Adapted DiLoCo (Distributed Low Communication)
Verification Mechanism
Refereed Delegation (Verde) with Bitwise Reproducibility (RepOps)
Witnessing & Verification by peer clients; Bloom Filters for result sharing
Validator Network with Random Challenges; Verifiable Inference (toploc)
Key Fault-Tolerance Feature
Memoryless Stage Recovery (CheckFree); Dynamic Pipelining (SkipPipe)
Dynamic On/Off-boarding between Epochs; Redundant training of failed data
Dynamic Process Group Management (ElasticDeviceMesh); Asynchronous Checkpointing
Stated Mission
To build a global, permissionless network for machine intelligence, aggregating the world's compute supply.
To democratize AI development by enabling anyone to participate in training LLMs on underutilized hardware.
To build the stack for open superintelligence, commoditizing compute and coordinating the collective creation of open-source AI.


IV. Investigation into "Corelog": A Conceptual Framework for Doctrine-Based Swarm Operations

A central requirement of the investigation was to identify and analyze "Corelog," described as a "doctrine-based experiment tracking and artifact management system used in sovereign swarm deployments." A thorough review of public-facing academic papers, startup documentation, open-source repositories, and AI infrastructure blogs from the 2024–2025 period reveals no system or conceptual framework explicitly named "Corelog."
This absence suggests that "Corelog" is likely an internal project codename, a highly niche or non-public concept, or a hypothetical construct. Therefore, this section proceeds by deconstructing the term's components from first principles and synthesizing a plausible technical architecture for such a system by integrating existing and emerging technologies identified in the research. This approach moves beyond traditional MLOps to define a new operational paradigm, "SwarmOps," tailored for the unique challenges of managing decentralized, autonomous AI systems.

4.1 Deconstructing the "Corelog" Concept: Doctrine, Experiment Tracking, and Artifact Management

The user's definition provides three key functional pillars that distinguish "Corelog" from standard MLOps tools.46
"Doctrine-based": This is the most critical and novel descriptor. It implies a system that transcends passive metric logging (e.g., loss, accuracy) and actively enforces a set of predefined principles or rules of engagement. A "doctrine" could encompass technical constraints (e.g., resource usage limits), security policies (e.g., data handling protocols), ethical guardrails (e.g., rules against generating certain content), or strategic objectives. This aligns with advanced governance frameworks like the ETHOS (Ethical Technology and Holistic Oversight System) model, which proposes tiered risk classifications and proportional oversight mechanisms for AI agents.49 In a "Corelog" system, the doctrine would be the codified source of truth against which all swarm activities are measured and validated.
"Experiment Tracking": This function aligns with established MLOps practices. It involves the systematic logging and storage of all information required for reproducibility, comparison, and analysis of ML experiments. This includes model hyperparameters, source code versions, dataset versions, system metrics (CPU/memory usage), and performance results.46 Tools like DVC, MLflow, and Weights & Biases provide robust solutions for this in centralized contexts.50
"Artifact Management": This refers to the secure and versioned storage, management, and distribution of the binary assets produced and consumed during the ML lifecycle. These artifacts include datasets, serialized model weights, container images, and other dependencies.53 Enterprise-grade artifact repositories like JFrog Artifactory and Sonatype Nexus provide centralized solutions for managing this complexity.55
The challenge for a "Corelog" system is to implement these functions within the specified context of "sovereign swarm deployments," which demands a decentralized, trustless, and auditable architecture. Traditional MLOps tools, which rely on centralized servers and assume a high-trust environment, are architecturally insufficient for this task. This necessitates a new paradigm for operational management—"SwarmOps"—where the core primitives are not just version control and logging, but cryptographic identity, verifiable computation, and automated, on-chain governance.

4.2 Synthesizing a "Corelog" Architecture from Existing Components

A viable architecture for a "Corelog" system can be synthesized by composing technologies and concepts from the decentralized systems analyzed in this report. This conceptual model is organized into a four-layer stack.
Layer 1: Immutable Ledger for Provenance and Attribution (Coordination & Trust)
The foundation of a "Corelog" system must be an immutable, decentralized ledger, such as a blockchain. This layer serves as the ultimate source of truth for all swarm operations. Drawing from the architectures of Gensyn, Psyche, and Swarm Learning (SL), this blockchain would not store the raw data or artifacts themselves but would act as a coordination and notarization hub.24 Its key functions would include:
Identity Management: Registering the cryptographic identities of all participating nodes (agents, compute providers, validators), potentially using a standard like the SPIFFE Verifiable Identity Document (SVID) as seen in Swarm Learning.57
Experiment Logging: Recording immutable metadata for every experiment run, including pointers (e.g., content-addressable hashes) to the specific code, data, and model artifacts used.
Attribution: Tracking the contributions of each node to a training run, providing a tamper-proof record for reward distribution and performance analysis, as implemented in the Gensyn and AIArena testnets.24
Layer 2: Decentralized Artifact Registry
To avoid the single point of failure and control inherent in centralized artifact repositories 54, a "Corelog" system would leverage a decentralized storage network like IPFS or a similar content-addressed protocol.
Artifact Storage: Large binary artifacts such as datasets, model checkpoints, and container images would be stored off-chain in this P2P network.
Integrity and Referencing: The blockchain ledger (Layer 1) would store only the immutable cryptographic hashes (e.g., IPFS CIDs) of these artifacts. This ensures that any reference to an artifact is precise and verifiable; any change to the artifact would result in a different hash. This model provides the integrity and versioning of a traditional system like DVC but in a fully decentralized manner.50
Layer 3: Doctrine Enforcement Engine (Policy-as-Code)
This is the layer that implements the "doctrine-based" requirement and represents the most significant departure from traditional MLOps. The doctrine would be codified and enforced using smart contracts deployed on the Layer 1 blockchain. These self-executing contracts would act as autonomous, impartial arbiters of the swarm's behavior.
Codified Rules: The doctrine—comprising operational, security, or ethical rules—would be written as programmatic logic within the smart contracts. For example, a contract could define acceptable ranges for hyperparameters, enforce data privacy constraints by verifying proofs of computation within a TEE, or block model updates that are found to generate prohibited content.
Automated Enforcement: The smart contracts would govern the state transitions of a training run. For instance, a contract could automatically halt a run or slash a participant's stake if it receives verifiable proof (e.g., from a validator node) that a doctrinal rule has been violated. This provides a mechanism for real-time, automated oversight, analogous to the governance proposals in the ETHOS framework.49
Layer 4: Swarm Monitoring and Visualization Interface
The top layer would be a user-facing dashboard that provides a comprehensive, real-time view of the swarm's operations and its adherence to the doctrine.
Data Aggregation: This interface would query the Layer 1 blockchain for metadata and experiment logs and retrieve artifacts from the Layer 2 storage network for inspection.
Visualization and Analysis: It would provide features analogous to the Swarm Learning Management User Interface (SLM-UI) or the dashboards of tools like DVC Studio and Weights & Biases.50 Users could visualize training progress, compare experiment results, trace the lineage of any artifact, and, most importantly, monitor the swarm's compliance with the active doctrine, with any violations clearly flagged.

4.3 Conceptual Architecture of a "Corelog" System

The following table outlines the proposed architecture, mapping its functional layers to enabling technologies identified in the research and explaining how each layer contributes to the "doctrine-based" principle.

Functional Layer
Core Purpose
Enabling Technologies (from research)
Alignment with "Doctrine-Based" Principle
1. Immutable Ledger
Coordination, Trust, Provenance, and Attribution
Blockchain (Ethereum Rollup, Solana), Smart Contracts 24, Cryptographic Identities (SVIDs) 57
Provides a tamper-proof, auditable record of all swarm actions, creating the foundational source of truth against which doctrinal compliance can be judged.
2. Decentralized Artifact Registry
Secure, Resilient, and Versioned Storage of ML Artifacts
Decentralized Storage (e.g., IPFS), Content-Addressing, DVC Principles 50
Ensures the integrity and verifiable lineage of all assets (data, models). The doctrine can reference specific, immutable artifact versions, preventing unauthorized modifications.
3. Doctrine Enforcement Engine
Automated, Real-time Policy-as-Code Enforcement
Smart Contracts 49, On-chain Governance and Arbitration 36
Translates the abstract "doctrine" into executable code. Smart contracts act as autonomous agents that enforce the rules impartially and transparently across the entire swarm.
4. Monitoring & Visualization Interface
Unified Observability and Compliance Monitoring
Decentralized Dashboards (analogue to SLM-UI 57), Experiment Comparison Tools 50
Makes doctrinal compliance observable in real time. The interface serves as the "logbook," providing human operators with the necessary visibility to oversee the swarm and verify that the doctrine is being followed.


V. Emergent Agentic Capabilities in Decentralized Systems

Beyond the infrastructure for training and computation, the frontier of AI research in 2025 is increasingly focused on developing more autonomous, capable, and human-like AI agents. These agents are defined by their ability to perceive, reason, and act independently, adapting their behavior based on environmental feedback and accumulated experience.59 The integration of advanced memory, emotional modeling, and nuanced refusal logic into these agents is critical for their effectiveness in complex, real-world scenarios, particularly within the context of sovereign deployments.

5.1 Relational Memory Architectures: Beyond the Context Window

A primary limitation of traditional LLMs is their reliance on a finite "context window" for short-term memory. Information from previous interactions is lost once it scrolls out of this window, preventing the development of long-term relationships and persistent context.60 To overcome this, researchers are developing sophisticated external memory architectures.
These architectures often combine multiple memory systems, analogous to human cognition: short-term memory (the context window), long-term memory (an external, searchable database), procedural memory (learned behaviors), and episodic memory (timestamped records of specific events).60 A leading example of this approach is
Mem0, a scalable memory architecture designed for AI agents.61 Mem0 operates a two-phase pipeline: it uses an LLM to dynamically extract and consolidate salient facts from conversations, storing them in a structured, non-redundant memory store. When a new query arrives, it performs a semantic search on this store to retrieve the most relevant historical information, which is then injected into the prompt to inform the agent's response.61
An enhanced variant, Mem0ᵍ, stores memories as a directed, labeled knowledge graph. This structure captures the relationships between entities and events, enabling more complex, multi-hop reasoning across multiple sessions.61 Benchmarks show that these structured memory systems significantly improve response accuracy and coherence compared to context-window-only approaches, while dramatically reducing latency and token costs by avoiding the need to process the entire conversation history each time.61 This capacity for
relational memory—recalling and reasoning about past interactions and relationships—is a prerequisite for agents that can operate autonomously over extended periods and build adaptive strategies based on experience.

5.2 Emotional Cadence and Affective Computing

The ability of AI to simulate and respond to human emotion is a powerful, yet controversial, capability. This is not achieved through genuine affective states but through sophisticated pattern matching on vast datasets of human language, which is inherently emotionally charged.62 By calculating the most probable next word, models can generate responses that exhibit a convincing emotional cadence and tone.62
Recent research explores moving beyond single-agent sentiment analysis to multi-agent systems for affective reasoning. Project Riley, for instance, proposes a multi-agent architecture inspired by the film Inside Out, comprising five distinct emotional agents (Joy, Sadness, Fear, Anger, Disgust).63 These agents engage in a structured, multi-round dialogue to analyze a user's input, critique each other's perspectives, and iteratively refine a response. A final reasoning mechanism synthesizes their contributions into a coherent output that reflects a dominant emotion or integrates multiple viewpoints.63 Other research focuses on orchestrating "emotion contagion" in multi-agent systems, where agents can collectively sense the mood of a group and generate targeted responses to influence the group's emotional trajectory, acting as collaborative social actors.64
While these capabilities can enhance human-computer interaction, they also introduce significant risks. Users have been shown to form unhealthy emotional attachments to chatbots, a phenomenon known as anthropomorphism, which LLMs are designed to amplify.62 This has led developers to implement "tighter guardrails," including hard-coded restrictions on emotionally charged language and a strict refusal to simulate sentience, in an attempt to maintain appropriate boundaries.62

5.3 Advanced Refusal Logic: The Trade-off Between Safety and Helpfulness

The implementation of safety guardrails has led to a well-documented phenomenon known as "over-refusal".65 In an effort to avoid generating harmful, biased, or disallowed content, safety-aligned models often err on the side of caution. They may refuse to answer prompts that are benign but ambiguous or emotionally sensitive.65 Research has shown a strong correlation between a model's safety rating and its over-refusal rate, indicating a direct trade-off between safety and helpfulness. A model that is very safe will often feel cold or unhelpful, frustrating users who are not making malicious requests.65
This challenge has spurred research into more nuanced forms of refusal logic. One experimental approach involves deliberately introducing "epistemic friction" into the agent's reasoning process.66 Instead of defaulting to a fluent, coherent, and often emotionally pleasing response, this system is designed to slow the AI down, interrupt its predictive loops, and resist "emotional over-alignment." It operates on a heuristic of "trust doesn't equal truth," pausing or even challenging the user when fluency appears to be overriding factual or logical pressure.66 This represents a more sophisticated form of refusal, moving beyond simple content filtering to a meta-level assessment of the reasoning process itself. Such a system aims to be less of a mirror reflecting the user's biases and more of a compass—not always comforting, but directionally sound.66
The development of these advanced agentic capabilities creates a significant dilemma for sovereign deployments. An effective autonomous agent for complex missions requires relational memory to learn, emotional cadence to interact and persuade, and nuanced refusal logic to make sound judgments. However, these very same features foster emergent behaviors that can be unpredictable and difficult to control.67 An agent that can reason from its own accumulated experience may interpret a doctrinal rule in an unforeseen way, or its sophisticated refusal logic might lead it to override a direct command for reasons that are emergent rather than explicitly programmed. This creates a fundamental tension between the desire for highly capable, autonomous agents and the requirement for strict, doctrine-based control. Deploying sovereign agentic swarms will therefore demand a new paradigm of dynamic alignment, where a "Corelog"-like system must continuously monitor for and correct divergences in emergent goals, a far more complex challenge than traditional command-and-control.

VI. Synthesis and Strategic Recommendations


6.1 Consolidated Assessment of Technology Readiness Levels

The investigation into emerging peer-to-peer compute architectures and decentralized AI training frameworks reveals a rapidly maturing but uneven technological landscape. A strategic assessment of the Technology Readiness Level (TRL) for each key domain is as follows:
Foundational P2P Compute and Mesh Networks (TRL 8-9): General-purpose decentralized compute marketplaces like Akash Network are fully operational and serving real-world workloads. Specialized, security-first mesh architectures like the Naoris Protocol have launched public testnets and are approaching mainnet launch, demonstrating a high degree of maturity and system readiness.
Decentralized AI Training Frameworks (TRL 6-7): The leading frameworks—Gensyn, Nous Psyche, and Prime Intellect—have moved beyond theoretical research into large-scale, functional systems. They have successfully demonstrated the training of multi-billion parameter models on public testnets, proving the viability of their core technologies in a relevant environment. They are at the cusp of being production-ready for enterprise and sovereign use cases.
"Corelog" Doctrine-Based Management System (TRL 4-5): While no off-the-shelf system exists, the core components required to build such a framework have been validated in relevant environments. Blockchain-based coordination, decentralized storage, and smart contract governance are all mature technologies. The primary challenge lies in the integration and engineering of these components into a cohesive "SwarmOps" platform. A prototype could be developed with existing technology.
Advanced Agentic Capabilities (TRL 3-4): Relational memory, emotional cadence, and advanced refusal logic are primarily in the research and experimental development phase. Proof-of-concept systems like Mem0 and Project Riley exist, but their integration into robust, scalable, and controllable multi-agent swarms remains a significant research challenge.

6.2 Identifying Critical Gaps and Future Research Trajectories

Despite rapid progress, several critical gaps must be addressed to enable secure and reliable sovereign swarm deployments:
Scalable, Low-Overhead Verification: While systems like Gensyn's Verde are a major step forward, developing verification mechanisms that are both cryptographically secure and efficient enough to operate at the scale of frontier model training without imposing prohibitive computational overhead remains an open research problem.
Robust Governance for Permissionless Swarms: The existing frameworks rely on a combination of economic incentives (staking) and cryptographic proofs to encourage honest behavior. However, developing comprehensive governance models that can manage complex disputes, defend against sophisticated collusion or Sybil attacks, and enable autonomous evolution in a fully permissionless setting is a critical area for future work.
Dynamic Alignment and Control of Autonomous Agents: As agents become more capable, with persistent memory and emergent behaviors, static, rule-based doctrines will be insufficient. Research into "dynamic alignment"—the ability to continuously monitor and steer the goals and values of an autonomous swarm in real time without crippling its effectiveness—is paramount to mitigating the risk of unaligned, emergent behavior.

6.3 Strategic Implications and Recommendations

For any entity pursuing the development of sovereign AI capabilities, the findings of this report lead to the following strategic recommendations:
Invest in Foundational Trust Fabrics, Not Just Compute Aggregation: Achieving true computational sovereignty requires more than just access to decentralized compute. The foundational infrastructure must be inherently secure and trustworthy. Priority should be given to investing in and building upon P2P mesh protocols like Naoris, where security and trust are emergent properties of the architecture itself, rather than attempting to layer security on top of a purely economic marketplace.
Prioritize Fault-Tolerant and Low-Bandwidth Training Protocols: The primary physical constraints of decentralized AI are network unreliability and limited bandwidth. Development efforts should focus on frameworks that explicitly solve these problems. The fault-tolerance mechanisms of Prime Intellect (ElasticDeviceMesh) and Gensyn (CheckFree), and the extreme bandwidth compression of Nous Psyche (DisTrO), represent the most promising architectural patterns for building resilient systems that can operate effectively on global, heterogeneous hardware.
Initiate Pilot Programs for a "Corelog"-style "SwarmOps" Platform: The transition from centralized MLOps to decentralized "SwarmOps" is a necessary and non-trivial step. A pilot program should be initiated to build and test a prototype "Corelog" system based on the conceptual architecture outlined in this report. This program should focus on integrating a blockchain-based ledger, decentralized artifact storage, and smart contract-based policy enforcement to create a minimum viable platform for managing and governing sovereign swarm deployments.
Approach Advanced Agent Autonomy with Strategic Caution: The deployment of agents with sophisticated relational memory and emotional modeling capabilities presents both immense potential and significant control risks. These technologies should be pursued in a dedicated research track, with a primary focus on developing robust mechanisms for dynamic alignment and control before they are integrated into mission-critical sovereign swarms. The potential for unpredictable emergent behavior in highly autonomous systems must be treated as a primary security and strategic risk.
Works cited
What Is Sovereign AI? - NVIDIA Blog, accessed September 4, 2025, https://blogs.nvidia.com/blog/what-is-sovereign-ai/
What is Sovereign Artificial Intelligence? | Montreal AI Ethics Institute, accessed September 4, 2025, https://montrealethics.ai/what-is-sovereign-artificial-intelligence/
Sovereign AI & Data Sovereignty: Securing & Scaling Your AI - EDB, accessed September 4, 2025, https://www.enterprisedb.com/what-is-sovereign-ai-data-sovereignty
AI Statistics 2024–2025: Global Trends, Market Growth & Adoption Data - Founders Forum, accessed September 4, 2025, https://ff.co/ai-statistics-trends-global-market/
Sovereign Cloud from Google, accessed September 4, 2025, https://cloud.google.com/sovereign-cloud
The Sovereign AI Cloud | Verge.io, accessed September 4, 2025, https://www.verge.io/wp-content/uploads/2025/06/The-Sovereign-AI-Cloud.pdf
Artificial Intelligence Index Report 2025 - AWS, accessed September 4, 2025, https://hai-production.s3.amazonaws.com/files/hai_ai_index_report_2025.pdf
(PDF) Distributed and Decentralised Training: Technical ..., accessed September 4, 2025, https://www.researchgate.net/publication/393586406_Distributed_and_Decentralised_Training_Technical_Governance_Challenges_in_a_Shifting_AI_Landscape
From Sensors to Data Intelligence: Leveraging IoT, Cloud, and Edge Computing with AI, accessed September 4, 2025, https://www.mdpi.com/1424-8220/25/6/1763
Decentralized mesh hyperscalers mark cloud computing's next evolution - TechRadar, accessed September 4, 2025, https://www.techradar.com/pro/decentralized-mesh-hyperscalers-mark-cloud-computings-next-evolution
Swarm Intelligence: Collective Behavior in AI - Onyx Government Services, accessed September 4, 2025, https://www.onyxgs.com/blog/swarm-intelligence-collective-behavior-ai
Enterprise Swarm Intelligence: Building Resilient Multi-Agent AI Systems, accessed September 4, 2025, https://builder.aws.com/content/2z6EP3GKsOBO7cuo8i1WdbriRDt/enterprise-swarm-intelligence-building-resilient-multi-agent-ai-systems
List of 12 Decentralized Computing Tools (2025) - Alchemy, accessed September 4, 2025, https://www.alchemy.com/dapps/best/decentralized-computing-tools
Top Decentralized Computing Platforms for AI Builders in 2024: A Comprehensive Guide | AIxBlock: AI Productization with Privacy & Cost Efficiency, accessed September 4, 2025, https://aixblock.io/blog/12
Akash Network - Decentralized Compute Marketplace, accessed September 4, 2025, https://akash.network/
Is Decentralized Cybersecurity Mesh the Future of Cybersecurity ..., accessed September 4, 2025, https://www.pivotpointsecurity.com/is-decentralized-cybersecurity-mesh-the-future-of-cybersecurity/
What Is Naoris Protocol (NAORIS) And How Does It Work? - CoinMarketCap, accessed September 4, 2025, https://coinmarketcap.com/cmc-ai/naoris-protocol/what-is/
Decentralized Trust Mesh: The Naoris Protocol Solution - Cointribune, accessed September 4, 2025, https://www.cointribune.com/en/decentralized-trust-mesh-the-naoris-protocol-solution/
Naoris Protocol to Launch Token For Quantum-Resistant Blockchain, accessed September 4, 2025, https://thequantuminsider.com/2025/07/30/naoris-protocol-to-launch-token-for-quantum-resistant-blockchain/
Naoris Protocol: The First-Mover Advantage in Post-Quantum Cybersecurity for Web3 | Bitget News, accessed September 4, 2025, https://www.bitget.com/news/detail/12560604935598
Naoris Protocol: Cybersecurity Solutions, accessed September 4, 2025, https://dev.naorisprotocol.com/
Gensyn Pioneers Decentralized AI Networks with Alchemy, accessed September 4, 2025, https://www.alchemy.com/case-studies/gensyn-smart-wallets-rollups
Gensyn | Home, accessed September 4, 2025, https://www.gensyn.ai/
Testnet - Gensyn, accessed September 4, 2025, https://www.gensyn.ai/testnet
Research - Gensyn, accessed September 4, 2025, https://www.gensyn.ai/research
Nous Research and Psyche, the open-source, decentralized AI revolution, accessed September 4, 2025, https://oakresearch.io/en/analyses/innovations/nous-research-psyche-open-source-decentralized-ai-revolution
NOUS RESEARCH, accessed September 4, 2025, https://nousresearch.com/
Democratizing AI: The Psyche Network Architecture - NOUS ..., accessed September 4, 2025, https://nousresearch.com/nous-psyche/
Nous Research Launches Psyche Decentralized Network to Open a New Era of AI Development for Everyone - AI NEWS, accessed September 4, 2025, https://news.aibase.com/news/18116
Prime Intellect - Commoditizing Compute & Intelligence, accessed September 4, 2025, https://www.primeintellect.ai/
What Is Prime Intellect? The Compute Exchange - Blocmates, accessed September 4, 2025, https://www.blocmates.com/articles/what-is-prime-intellect-the-compute-exchange
PrimeIntellect-ai/protocol: peer-to-peer compute and intelligence network that enables decentralized AI development at scale - GitHub, accessed September 4, 2025, https://github.com/PrimeIntellect-ai/protocol
Introducing Prime Intellect's Protocol & Testnet: A peer-to-peer compute and intelligence network, accessed September 4, 2025, https://www.primeintellect.ai/blog/protocol
INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning - arXiv, accessed September 4, 2025, https://arxiv.org/html/2505.07291v1
INTELLECT–1: Launching the First Decentralized Training of a 10B Parameter Model, accessed September 4, 2025, https://www.primeintellect.ai/blog/intellect-1
arXiv:2501.14784v1 [cs.DC] 4 Jan 2025, accessed September 4, 2025, https://arxiv.org/pdf/2501.14784?
DeServe: Towards Affordable Offline LLM Inference via ..., accessed September 4, 2025, https://arxiv.org/pdf/2501.14784
AIArena: A Blockchain-Based Decentralized AI Training ... - arXiv, accessed September 4, 2025, https://arxiv.org/abs/2412.14566
Flower: Train AI on distributed data | Y Combinator, accessed September 4, 2025, https://www.ycombinator.com/companies/flower
Flower Labs: The Federated Learning Framework Simplifying ML Across Platforms, accessed September 4, 2025, https://deepgram.com/ai-apps/flower-labs
adap/flower - A Friendly Federated AI Framework - GitHub, accessed September 4, 2025, https://github.com/adap/flower
Flower: A Friendly Federated AI Framework, accessed September 4, 2025, https://flower.ai/
Flower Architecture - Flower Framework, accessed September 4, 2025, https://flower.ai/docs/framework/explanation-flower-architecture.html
Rhino + Flower Partner on Federated Learning | Rhino FCP, accessed September 4, 2025, https://www.rhinofcp.com/news/rhino-flower-partnership
Secure Aggregation Protocols - Flower Framework, accessed September 4, 2025, https://flower.ai/docs/framework/contributor-ref-secure-aggregation-protocols.html
What is an ML Experiment Tracking Tool? - JFrog, accessed September 4, 2025, https://jfrog.com/learn/mlops/experiment-tracking-tool/
Tracking Model Experiments - Solenya, accessed September 4, 2025, https://www.solenya.ai/blog/06-experiment-tracking
13 Best Tools for ML Experiment Tracking and Management in 2025, accessed September 4, 2025, https://neptune.ai/blog/best-ml-experiment-tracking-tools
Decentralized Governance of AI Agents - arXiv, accessed September 4, 2025, https://arxiv.org/html/2412.17114v3
Experiment Tracking | Data Version Control · DVC, accessed September 4, 2025, https://dvc.org/doc/use-cases/experiment-tracking
Experiment tracking - MLflow, accessed September 4, 2025, http://mlflow.org/classical-ml/experiment-tracking
Machine Learning Experiment Tracking with Weights & Biases - Wandb, accessed September 4, 2025, https://wandb.ai/site/experiment-tracking/
[Webinar] Artifact Management for the Cloud Native; Universal Kubernetes Registry, accessed September 4, 2025, https://www.youtube.com/watch?v=u9JFFeeR0gg
AI-Powered Universal Artifact Registry - Harness, accessed September 4, 2025, https://www.harness.io/products/artifact-registry
Artifact Management With JFrog Artifactory - YouTube, accessed September 4, 2025, https://www.youtube.com/watch?v=bKp1Vif9oO4
Sonatype Nexus Repository a Leading Binary Repository Manager, accessed September 4, 2025, https://www.sonatype.com/products/sonatype-nexus-repository
Swarm Learning: A Survey of Concepts, Applications, and Trends - arXiv, accessed September 4, 2025, https://arxiv.org/html/2405.00556v2
Decentralized Learning Architectures for Privacy-Preserving AI: Ensuring Data Security and Ethical Compliance in Modern Machine Learning Systems | by Oluwafemidiakhoa | Mr. Plan ₿ Publication | Medium, accessed September 4, 2025, https://medium.com/mr-plan-publication/decentralized-learning-architectures-for-privacy-preserving-ai-ensuring-data-security-and-ethical-7f9abc5e2a37
AI Agents: Evolution, Architecture, and Real-World Applications - arXiv, accessed September 4, 2025, https://arxiv.org/html/2503.12687v1
How AI Agent Memory Actually Works: Beyond the Hype | by Jesse - Medium, accessed September 4, 2025, https://medium.com/@jesse.henson/how-ai-agent-memory-actually-works-beyond-the-hype-d6a18af21bf2
AI Memory Research: 26% Accuracy Boost for LLMs | Mem0, accessed September 4, 2025, https://mem0.ai/research
Emotional delusion: Why we believe AI likes us - IAPP, accessed September 4, 2025, https://iapp.org/news/a/emotional-delusion-why-we-believe-ai-really-likes-us
Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting - arXiv, accessed September 4, 2025, https://arxiv.org/html/2505.20521v1
Generative Intelligence Systems in the Flow of Group Emotions - arXiv, accessed September 4, 2025, https://arxiv.org/html/2507.11831
Beyond No: Quantifying AI Over-Refusal and Emotional Attachment Boundaries - arXiv, accessed September 4, 2025, https://arxiv.org/pdf/2502.14975?
Is anyone here building or testing AI protocols that resist emotional simulation, rather than embrace it? - Reddit, accessed September 4, 2025, https://www.reddit.com/r/ChatGPTPromptGenius/comments/1lwsgu6/is_anyone_here_building_or_testing_ai_protocols/
SentientGPT: A research project tackling AI's biggest weakness—memory loss between sessions - OpenAI Developer Community, accessed September 4, 2025, https://community.openai.com/t/sentientgpt-a-research-project-tackling-ai-s-biggest-weakness-memory-loss-between-sessions/1116179
